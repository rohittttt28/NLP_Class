{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPclass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1Jlf/8ULbFtXV4rWlPHOj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohittttt28/NLP_Class/blob/master/NLPclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9taVO9GugVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "de120336-fece-4ef2-829c-eabe695c160a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdnLi443wU4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import random\n",
        "import string\n",
        "import io\n",
        "\n",
        "#Input of csv \n",
        "df=pd.read_csv('https://raw.githubusercontent.com/rohittttt28/News_Scrapy/master/review.csv',usecols=[\"Review Text\"]).rename(columns={\"Review Text\": \"Review\"}).dropna()\n",
        "\n",
        "#df['Review']=df['Review'].map(lambda x :x.lower()).map(lambda x:x.replace(\" \",\"\"))\n",
        "\n",
        "df['id']=[n for n in np.arange(len(df))]\n",
        "df=df.set_index('id')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVxAR2qmj4CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA3scvaqkeYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ccecf227-89da-4d3d-f801-7722b986f83b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Review\n",
              "id                                                   \n",
              "0   Absolutely wonderful - silky and sexy and comf...\n",
              "1   Love this dress!  it's sooo pretty.  i happene...\n",
              "2   I had such high hopes for this dress and reall...\n",
              "3   I love, love, love this jumpsuit. it's fun, fl...\n",
              "4   This shirt is very flattering to all due to th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anJ9Z9b_lw8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cdab80ea-3cb2-4bf8-93f0-7ffb17b7797c"
      },
      "source": [
        "df['Review'][1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnisJ3_RcUsz",
        "colab_type": "text"
      },
      "source": [
        "NLTK \n",
        "step 1: Tokenizing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchr9pBYXx-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk \n",
        "from nltk import word_tokenize,wordpunct_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_iD6lcfY8fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df['Tokens']=df['Review'].map(lambda x:tokenizer.tokenize(x))\n",
        "df['Tokens']=df['Review'].apply(lambda x:tokenizer.tokenize(x))\n",
        "x1=df.drop(['Review'],axis=1).copy(deep=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mBz4_HOZ5YJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "df8b08f1-5716-4bb2-ded0-14bed151c44c"
      },
      "source": [
        "x1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Absolutely, wonderful, -, silky, and, sexy, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Love, this, dress, !, it, ', s, sooo, pretty,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[I, had, such, high, hopes, for, this, dress, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[I, love, ,, love, ,, love, this, jumpsuit, .,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[This, shirt, is, very, flattering, to, all, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22636</th>\n",
              "      <td>[I, was, very, happy, to, snag, this, dress, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>[It, reminds, me, of, maternity, clothes, ., s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22638</th>\n",
              "      <td>[This, fit, well, ,, but, the, top, was, very,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22639</th>\n",
              "      <td>[I, bought, this, dress, for, a, wedding, i, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22640</th>\n",
              "      <td>[This, dress, in, a, lovely, platinum, is, fem...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tokens\n",
              "id                                                      \n",
              "0      [Absolutely, wonderful, -, silky, and, sexy, a...\n",
              "1      [Love, this, dress, !, it, ', s, sooo, pretty,...\n",
              "2      [I, had, such, high, hopes, for, this, dress, ...\n",
              "3      [I, love, ,, love, ,, love, this, jumpsuit, .,...\n",
              "4      [This, shirt, is, very, flattering, to, all, d...\n",
              "...                                                  ...\n",
              "22636  [I, was, very, happy, to, snag, this, dress, a...\n",
              "22637  [It, reminds, me, of, maternity, clothes, ., s...\n",
              "22638  [This, fit, well, ,, but, the, top, was, very,...\n",
              "22639  [I, bought, this, dress, for, a, wedding, i, h...\n",
              "22640  [This, dress, in, a, lovely, platinum, is, fem...\n",
              "\n",
              "[22641 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6PNnW8cjIo",
        "colab_type": "text"
      },
      "source": [
        "STEP 2: Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZvoMuLeaq01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "16dd1221-5fbf-4c42-fd42-1f6e8c8f9526"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def filter_me_bitch(x):\n",
        "  filtered_sentence = [] \n",
        "  for w in x: \n",
        "      if w not in stop_words: \n",
        "          filtered_sentence.append(w)\n",
        "  return filtered_sentence         \n",
        "x1['Filter_tok']=x1['Tokens'].apply(lambda x:filter_me_bitch(x))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwkHaEqeK3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "52b849e8-9d87-493a-a7a9-b3fe80d741a6"
      },
      "source": [
        "x1\n",
        "print(x1['Tokens'][1])\n",
        "print(x1['Filter_tok'][1])\n",
        "print(len(x1['Tokens'][1]))\n",
        "print(len(x1['Filter_tok'][1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Love', 'this', 'dress', '!', 'it', \"'\", 's', 'sooo', 'pretty', '.', 'i', 'happened', 'to', 'find', 'it', 'in', 'a', 'store', ',', 'and', 'i', \"'\", 'm', 'glad', 'i', 'did', 'bc', 'i', 'never', 'would', 'have', 'ordered', 'it', 'online', 'bc', 'it', \"'\", 's', 'petite', '.', 'i', 'bought', 'a', 'petite', 'and', 'am', '5', \"'\", '8', '\".', 'i', 'love', 'the', 'length', 'on', 'me', '-', 'hits', 'just', 'a', 'little', 'below', 'the', 'knee', '.', 'would', 'definitely', 'be', 'a', 'true', 'midi', 'on', 'someone', 'who', 'is', 'truly', 'petite', '.']\n",
            "['Love', 'dress', '!', \"'\", 'sooo', 'pretty', '.', 'happened', 'find', 'store', ',', \"'\", 'glad', 'bc', 'never', 'would', 'ordered', 'online', 'bc', \"'\", 'petite', '.', 'bought', 'petite', '5', \"'\", '8', '\".', 'love', 'length', '-', 'hits', 'little', 'knee', '.', 'would', 'definitely', 'true', 'midi', 'someone', 'truly', 'petite', '.']\n",
            "78\n",
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmsb413bgZit",
        "colab_type": "text"
      },
      "source": [
        "Step 3:Let's stem "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5WC_p2ffhQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer() # is it a ps ,you write after every script ,,,Hell NOOO\n",
        "def stem_lightly(x):\n",
        "  cd=[]\n",
        "  for i in x:\n",
        "    cd.append(ps.stem(i))\n",
        "  return cd\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P83a1TKPhTcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x1['stem_it']=x1['Filter_tok'].apply(lambda x:ps.stem(x)) #not working because we need a list le me**Happy diwali\n",
        "x1['stem_it']=x1['Filter_tok'].apply(lambda x:stem_lightly(x)) # yah it worked !!!baap baap hota h \n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmwG4cMpjW9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "30a4fafb-1317-4575-e058-2979e8f441ed"
      },
      "source": [
        "x1['stem_it']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0               [absolut, wonder, -, silki, sexi, comfort]\n",
              "1        [love, dress, !, ', sooo, pretti, ., happen, f...\n",
              "2        [I, high, hope, dress, realli, want, work, ., ...\n",
              "3        [I, love, ,, love, ,, love, jumpsuit, ., ', fu...\n",
              "4        [thi, shirt, flatter, due, adjust, front, tie,...\n",
              "                               ...                        \n",
              "22636    [I, happi, snag, dress, great, price, !, ', ea...\n",
              "22637    [It, remind, matern, cloth, ., soft, ,, stretc...\n",
              "22638    [thi, fit, well, ,, top, see, ., never, would,...\n",
              "22639    [I, bought, dress, wed, summer, ,, ', cute, .,...\n",
              "22640    [thi, dress, love, platinum, feminin, fit, per...\n",
              "Name: stem_it, Length: 22641, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rvVmY3dj0SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YFJEwBAj-mv",
        "colab_type": "text"
      },
      "source": [
        "Step 4: Lemmatization # spelling sahi samjh lena "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFCqMy0CkRCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b1039a56-8cc3-4a86-b187-aaae5b4ccaf6"
      },
      "source": [
        "nltk.download('wordnet') #download wali cheez pehle kiya kr \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "def lemmatizz_slowly(x):\n",
        "  cd=[]\n",
        "  for i in x:\n",
        "    cd.append(lemmatizer.lemmatize(i))\n",
        "  return cd\n",
        "\n",
        "x1['lemma']=x1['Filter_tok'].apply(lambda x:lemmatizz_slowly(x))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJviOST8k5Og",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "83a0560b-bf98-4f74-d99e-7d3eb93a11f9"
      },
      "source": [
        "x1\n",
        "#abhi itna hi ...to be continued!! "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Filter_tok</th>\n",
              "      <th>lemma</th>\n",
              "      <th>stem_it</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Absolutely, wonderful, -, silky, and, sexy, a...</td>\n",
              "      <td>[Absolutely, wonderful, -, silky, sexy, comfor...</td>\n",
              "      <td>[Absolutely, wonderful, -, silky, sexy, comfor...</td>\n",
              "      <td>[absolut, wonder, -, silki, sexi, comfort]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Love, this, dress, !, it, ', s, sooo, pretty,...</td>\n",
              "      <td>[Love, dress, !, ', sooo, pretty, ., happened,...</td>\n",
              "      <td>[Love, dress, !, ', sooo, pretty, ., happened,...</td>\n",
              "      <td>[love, dress, !, ', sooo, pretti, ., happen, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[I, had, such, high, hopes, for, this, dress, ...</td>\n",
              "      <td>[I, high, hopes, dress, really, wanted, work, ...</td>\n",
              "      <td>[I, high, hope, dress, really, wanted, work, ....</td>\n",
              "      <td>[I, high, hope, dress, realli, want, work, ., ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[I, love, ,, love, ,, love, this, jumpsuit, .,...</td>\n",
              "      <td>[I, love, ,, love, ,, love, jumpsuit, ., ', fu...</td>\n",
              "      <td>[I, love, ,, love, ,, love, jumpsuit, ., ', fu...</td>\n",
              "      <td>[I, love, ,, love, ,, love, jumpsuit, ., ', fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[This, shirt, is, very, flattering, to, all, d...</td>\n",
              "      <td>[This, shirt, flattering, due, adjustable, fro...</td>\n",
              "      <td>[This, shirt, flattering, due, adjustable, fro...</td>\n",
              "      <td>[thi, shirt, flatter, due, adjust, front, tie,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22636</th>\n",
              "      <td>[I, was, very, happy, to, snag, this, dress, a...</td>\n",
              "      <td>[I, happy, snag, dress, great, price, !, ', ea...</td>\n",
              "      <td>[I, happy, snag, dress, great, price, !, ', ea...</td>\n",
              "      <td>[I, happi, snag, dress, great, price, !, ', ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22637</th>\n",
              "      <td>[It, reminds, me, of, maternity, clothes, ., s...</td>\n",
              "      <td>[It, reminds, maternity, clothes, ., soft, ,, ...</td>\n",
              "      <td>[It, reminds, maternity, clothes, ., soft, ,, ...</td>\n",
              "      <td>[It, remind, matern, cloth, ., soft, ,, stretc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22638</th>\n",
              "      <td>[This, fit, well, ,, but, the, top, was, very,...</td>\n",
              "      <td>[This, fit, well, ,, top, see, ., never, would...</td>\n",
              "      <td>[This, fit, well, ,, top, see, ., never, would...</td>\n",
              "      <td>[thi, fit, well, ,, top, see, ., never, would,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22639</th>\n",
              "      <td>[I, bought, this, dress, for, a, wedding, i, h...</td>\n",
              "      <td>[I, bought, dress, wedding, summer, ,, ', cute...</td>\n",
              "      <td>[I, bought, dress, wedding, summer, ,, ', cute...</td>\n",
              "      <td>[I, bought, dress, wed, summer, ,, ', cute, .,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22640</th>\n",
              "      <td>[This, dress, in, a, lovely, platinum, is, fem...</td>\n",
              "      <td>[This, dress, lovely, platinum, feminine, fits...</td>\n",
              "      <td>[This, dress, lovely, platinum, feminine, fit,...</td>\n",
              "      <td>[thi, dress, love, platinum, feminin, fit, per...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22641 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tokens  ...                                            stem_it\n",
              "id                                                        ...                                                   \n",
              "0      [Absolutely, wonderful, -, silky, and, sexy, a...  ...         [absolut, wonder, -, silki, sexi, comfort]\n",
              "1      [Love, this, dress, !, it, ', s, sooo, pretty,...  ...  [love, dress, !, ', sooo, pretti, ., happen, f...\n",
              "2      [I, had, such, high, hopes, for, this, dress, ...  ...  [I, high, hope, dress, realli, want, work, ., ...\n",
              "3      [I, love, ,, love, ,, love, this, jumpsuit, .,...  ...  [I, love, ,, love, ,, love, jumpsuit, ., ', fu...\n",
              "4      [This, shirt, is, very, flattering, to, all, d...  ...  [thi, shirt, flatter, due, adjust, front, tie,...\n",
              "...                                                  ...  ...                                                ...\n",
              "22636  [I, was, very, happy, to, snag, this, dress, a...  ...  [I, happi, snag, dress, great, price, !, ', ea...\n",
              "22637  [It, reminds, me, of, maternity, clothes, ., s...  ...  [It, remind, matern, cloth, ., soft, ,, stretc...\n",
              "22638  [This, fit, well, ,, but, the, top, was, very,...  ...  [thi, fit, well, ,, top, see, ., never, would,...\n",
              "22639  [I, bought, this, dress, for, a, wedding, i, h...  ...  [I, bought, dress, wed, summer, ,, ', cute, .,...\n",
              "22640  [This, dress, in, a, lovely, platinum, is, fem...  ...  [thi, dress, love, platinum, feminin, fit, per...\n",
              "\n",
              "[22641 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYf29sWXlnHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}